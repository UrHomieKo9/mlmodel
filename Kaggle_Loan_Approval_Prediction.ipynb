{
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 2047352,
          "sourceType": "datasetVersion",
          "datasetId": 1226448
        }
      ],
      "dockerImageVersionId": 30746,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Kaggle Loan Approval Prediction",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UrHomieKo9/mlmodel/blob/main/Kaggle_Loan_Approval_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'loan-approval-prediction:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1226448%2F2047352%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240722%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240722T053225Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D3ab1138c7a7bc4b5228aef38cdc77e5109254b5ed52e903c77853496a0c23c3c3da50001faa7d30eddc50ecbfe460c1da3294d194f41b19cf36172ed507a46ca327cd4794e53c8a6a4ffd582ee6a5a05063b766d2cada742bd4480870b05ab22090fe4454171257876bff1205f1fbdcd051349b6fc6e39362ea449aaabe03e932720748ef5439b876b9a607e0ac64285647a3227f809b6ef0e03613e750a92590884b48cc45e179e023560e387ec1a569d17ed9f230bdca528e4d39690c691e54ec6c5398be0caa708acbbde043f7f7f958e0e42617225b9a348e3649dedcc21e6e93555f9814aeb83aa77978a1982b8d0dfac82e0956cab185284f019fe8fd9'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "_Ge9wgNJ7hAQ"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error\n",
        "import numpy as np"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.status.busy": "2024-07-13T23:00:01.994915Z",
          "iopub.execute_input": "2024-07-13T23:00:01.99537Z",
          "iopub.status.idle": "2024-07-13T23:00:02.0097Z",
          "shell.execute_reply.started": "2024-07-13T23:00:01.995336Z",
          "shell.execute_reply": "2024-07-13T23:00:02.008117Z"
        },
        "trusted": true,
        "id": "2ysdXPyA7hAU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loan Eligibility Prediction\n",
        "\n",
        "This notebook demonstrates the process of predicting loan eligibility based on customer details. The steps include data preprocessing, model training, and generating predictions for the test dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "BmqRb_Gq7hAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Akuus9QR8Djj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Load Datasets"
      ],
      "metadata": {
        "id": "jrRX3-Oh7hAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "train_data = pd.read_csv('Training Dataset.csv')\n",
        "test_data = pd.read_csv('Test Dataset.csv')\n",
        "sample_submission = pd.read_csv('Sample_Submission.csv')\n",
        "\n",
        "# Display the first few rows of each dataset\n",
        "print(\"Training Data:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nTest Data:\")\n",
        "print(test_data.head())\n",
        "\n",
        "print(\"\\nSample Submission:\")\n",
        "print(sample_submission.head())\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-13T23:00:10.086599Z",
          "iopub.execute_input": "2024-07-13T23:00:10.087098Z",
          "iopub.status.idle": "2024-07-13T23:00:10.126827Z",
          "shell.execute_reply.started": "2024-07-13T23:00:10.087048Z",
          "shell.execute_reply": "2024-07-13T23:00:10.125564Z"
        },
        "trusted": true,
        "id": "kjRIu02D7hAX",
        "outputId": "2889d97c-8d27-47fc-f24b-fe18f56c3896",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data:\n",
            "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
            "0  LP001002   Male      No          0      Graduate            No   \n",
            "1  LP001003   Male     Yes          1      Graduate            No   \n",
            "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
            "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
            "4  LP001008   Male      No          0      Graduate            No   \n",
            "\n",
            "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
            "0             5849                0.0         NaN             360.0   \n",
            "1             4583             1508.0       128.0             360.0   \n",
            "2             3000                0.0        66.0             360.0   \n",
            "3             2583             2358.0       120.0             360.0   \n",
            "4             6000                0.0       141.0             360.0   \n",
            "\n",
            "   Credit_History Property_Area Loan_Status  \n",
            "0             1.0         Urban           Y  \n",
            "1             1.0         Rural           N  \n",
            "2             1.0         Urban           Y  \n",
            "3             1.0         Urban           Y  \n",
            "4             1.0         Urban           Y  \n",
            "\n",
            "Test Data:\n",
            "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
            "0  LP001015   Male     Yes          0      Graduate            No   \n",
            "1  LP001022   Male     Yes          1      Graduate            No   \n",
            "2  LP001031   Male     Yes          2      Graduate            No   \n",
            "3  LP001035   Male     Yes          2      Graduate            No   \n",
            "4  LP001051   Male      No          0  Not Graduate            No   \n",
            "\n",
            "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
            "0             5720                  0       110.0             360.0   \n",
            "1             3076               1500       126.0             360.0   \n",
            "2             5000               1800       208.0             360.0   \n",
            "3             2340               2546       100.0             360.0   \n",
            "4             3276                  0        78.0             360.0   \n",
            "\n",
            "   Credit_History Property_Area  \n",
            "0             1.0         Urban  \n",
            "1             1.0         Urban  \n",
            "2             1.0         Urban  \n",
            "3             NaN         Urban  \n",
            "4             1.0         Urban  \n",
            "\n",
            "Sample Submission:\n",
            "    Loan_ID Loan_Status\n",
            "0  LP001015           N\n",
            "1  LP001022           N\n",
            "2  LP001031           N\n",
            "3  LP001035           N\n",
            "4  LP001051           N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Handle Missing Values"
      ],
      "metadata": {
        "id": "1nTbjzow7hAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values in training data\n",
        "train_data['Gender'] = train_data['Gender'].fillna(train_data['Gender'].mode()[0])\n",
        "train_data['Married'] = train_data['Married'].fillna(train_data['Married'].mode()[0])\n",
        "train_data['Dependents'] = train_data['Dependents'].fillna(train_data['Dependents'].mode()[0])\n",
        "train_data['Self_Employed'] = train_data['Self_Employed'].fillna(train_data['Self_Employed'].mode()[0])\n",
        "train_data['Credit_History'] = train_data['Credit_History'].fillna(train_data['Credit_History'].mode()[0])\n",
        "train_data['LoanAmount'] = train_data['LoanAmount'].fillna(train_data['LoanAmount'].mean())\n",
        "train_data['Loan_Amount_Term'] = train_data['Loan_Amount_Term'].fillna(train_data['Loan_Amount_Term'].mean())\n",
        "\n",
        "# Handle missing values in testing data\n",
        "test_data['Gender'] = test_data['Gender'].fillna(test_data['Gender'].mode()[0])\n",
        "test_data['Married'] = test_data['Married'].fillna(test_data['Married'].mode()[0])\n",
        "test_data['Dependents'] = test_data['Dependents'].fillna(test_data['Dependents'].mode()[0])\n",
        "test_data['Self_Employed'] = test_data['Self_Employed'].fillna(test_data['Self_Employed'].mode()[0])\n",
        "test_data['Credit_History'] = test_data['Credit_History'].fillna(test_data['Credit_History'].mode()[0])\n",
        "test_data['LoanAmount'] = test_data['LoanAmount'].fillna(test_data['LoanAmount'].mean())\n",
        "test_data['Loan_Amount_Term'] = test_data['Loan_Amount_Term'].fillna(test_data['Loan_Amount_Term'].mean())\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-13T23:00:16.240811Z",
          "iopub.execute_input": "2024-07-13T23:00:16.241315Z",
          "iopub.status.idle": "2024-07-13T23:00:16.268315Z",
          "shell.execute_reply.started": "2024-07-13T23:00:16.241278Z",
          "shell.execute_reply": "2024-07-13T23:00:16.26711Z"
        },
        "trusted": true,
        "id": "x0yUtSaT7hAY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Encode Categorical Variables"
      ],
      "metadata": {
        "id": "Pu11RHQW7hAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode categorical variables\n",
        "train_data = pd.get_dummies(train_data, columns=['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area'], drop_first=True)\n",
        "test_data = pd.get_dummies(test_data, columns=['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area'], drop_first=True)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-13T23:00:20.62586Z",
          "iopub.execute_input": "2024-07-13T23:00:20.626319Z",
          "iopub.status.idle": "2024-07-13T23:00:20.652388Z",
          "shell.execute_reply.started": "2024-07-13T23:00:20.626286Z",
          "shell.execute_reply": "2024-07-13T23:00:20.65095Z"
        },
        "trusted": true,
        "id": "qRQdFoNc7hAa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Split Training Data into Training and Validation Sets"
      ],
      "metadata": {
        "id": "0fQg699C7hAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the training data into training and validation sets\n",
        "X = train_data.drop(['Loan_ID', 'Loan_Status'], axis=1)\n",
        "y = train_data['Loan_Status']\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-13T23:00:34.451212Z",
          "iopub.execute_input": "2024-07-13T23:00:34.451635Z",
          "iopub.status.idle": "2024-07-13T23:00:34.462911Z",
          "shell.execute_reply.started": "2024-07-13T23:00:34.451603Z",
          "shell.execute_reply": "2024-07-13T23:00:34.461735Z"
        },
        "trusted": true,
        "id": "4W2zB3DQ7hAb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Scale Numerical Features"
      ],
      "metadata": {
        "id": "Bizdij6h7hAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']] = scaler.fit_transform(X_train[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']])\n",
        "X_val[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']] = scaler.transform(X_val[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']])\n",
        "test_data[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']] = scaler.transform(test_data[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-13T23:00:39.557293Z",
          "iopub.execute_input": "2024-07-13T23:00:39.55774Z",
          "iopub.status.idle": "2024-07-13T23:00:39.579913Z",
          "shell.execute_reply.started": "2024-07-13T23:00:39.557706Z",
          "shell.execute_reply": "2024-07-13T23:00:39.578462Z"
        },
        "trusted": true,
        "id": "XCOOrIPO7hAb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Train a Logistic Regression Model"
      ],
      "metadata": {
        "id": "U9E8is5-7hAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Logistic Regression model\n",
        "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_val_pred_log = log_reg.predict(X_val)\n",
        "\n",
        "# Evaluate the Logistic Regression model\n",
        "accuracy_log = accuracy_score(y_val, y_val_pred_log)\n",
        "classification_rep_log = classification_report(y_val, y_val_pred_log)\n",
        "\n",
        "print(\"Logistic Regression Model:\")\n",
        "print(f\"Accuracy: {accuracy_log}\")\n",
        "print(f\"Classification Report:\\n{classification_rep_log}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-13T23:00:44.152187Z",
          "iopub.execute_input": "2024-07-13T23:00:44.152643Z",
          "iopub.status.idle": "2024-07-13T23:00:44.204738Z",
          "shell.execute_reply.started": "2024-07-13T23:00:44.152607Z",
          "shell.execute_reply": "2024-07-13T23:00:44.203082Z"
        },
        "trusted": true,
        "id": "Vx1oN_h67hAb",
        "outputId": "9ba7ae0e-4633-4481-cd70-78df5e1bcc8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Model:\n",
            "Accuracy: 0.7886178861788617\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N       0.95      0.42      0.58        43\n",
            "           Y       0.76      0.99      0.86        80\n",
            "\n",
            "    accuracy                           0.79       123\n",
            "   macro avg       0.85      0.70      0.72       123\n",
            "weighted avg       0.83      0.79      0.76       123\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Train a Random Forest Model"
      ],
      "metadata": {
        "id": "qQa7g-wq7hAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Random Forest model\n",
        "rf_clf = RandomForestClassifier(random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_val_pred_rf = rf_clf.predict(X_val)\n",
        "\n",
        "# Evaluate the Random Forest model\n",
        "accuracy_rf = accuracy_score(y_val, y_val_pred_rf)\n",
        "classification_rep_rf = classification_report(y_val, y_val_pred_rf)\n",
        "\n",
        "print(\"\\nRandom Forest Model:\")\n",
        "print(f\"Accuracy: {accuracy_rf}\")\n",
        "print(f\"Classification Report:\\n{classification_rep_rf}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-13T23:00:49.586813Z",
          "iopub.execute_input": "2024-07-13T23:00:49.587265Z",
          "iopub.status.idle": "2024-07-13T23:00:49.900698Z",
          "shell.execute_reply.started": "2024-07-13T23:00:49.58723Z",
          "shell.execute_reply": "2024-07-13T23:00:49.899371Z"
        },
        "trusted": true,
        "id": "76SsAyRz7hAc",
        "outputId": "c8c1d904-9054-41b5-ddf6-69fbc02718ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest Model:\n",
            "Accuracy: 0.7804878048780488\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N       0.90      0.42      0.57        43\n",
            "           Y       0.76      0.97      0.85        80\n",
            "\n",
            "    accuracy                           0.78       123\n",
            "   macro avg       0.83      0.70      0.71       123\n",
            "weighted avg       0.81      0.78      0.75       123\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, ENCODE THE TARGET VARIABLES, AND make sure you're using the LabelEncoder consistently:"
      ],
      "metadata": {
        "id": "kFMp81jz7hAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create the LabelEncoder\n",
        "loan_status_le = LabelEncoder()\n",
        "\n",
        "# Fit the encoder on the entire training set\n",
        "loan_status_le.fit(train_data['Loan_Status'])\n",
        "\n",
        "# Transform the training data\n",
        "y = loan_status_le.transform(train_data['Loan_Status'])\n",
        "\n",
        "# Split the data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-13T23:00:54.198886Z",
          "iopub.execute_input": "2024-07-13T23:00:54.199982Z",
          "iopub.status.idle": "2024-07-13T23:00:54.210442Z",
          "shell.execute_reply.started": "2024-07-13T23:00:54.199944Z",
          "shell.execute_reply": "2024-07-13T23:00:54.208915Z"
        },
        "trusted": true,
        "id": "QiSnLRVi7hAc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When making predictions on the test set, you'll need to decode the predictions back to 'Y' and 'N':"
      ],
      "metadata": {
        "id": "OoOlNV5C7hAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test set\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, y_train)\n",
        "X_test = test_data.drop('Loan_ID', axis=1)\n",
        "test_preds_lr = lin_reg.predict(X_test)\n",
        "test_preds_lr_binary = np.round(test_preds_lr).astype(int)\n",
        "\n",
        "# Decode predictions\n",
        "test_preds_decoded = loan_status_le.inverse_transform(test_preds_lr_binary)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-13T23:00:58.721056Z",
          "iopub.execute_input": "2024-07-13T23:00:58.7222Z",
          "iopub.status.idle": "2024-07-13T23:00:58.738949Z",
          "shell.execute_reply.started": "2024-07-13T23:00:58.72216Z",
          "shell.execute_reply": "2024-07-13T23:00:58.737721Z"
        },
        "trusted": true,
        "id": "qghsRqA07hAc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When training your models, use the transformed y values"
      ],
      "metadata": {
        "id": "cX1-ttA87hAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Random Forest model (or whichever model you choose as final_model)\n",
        "rf_clf = RandomForestClassifier(random_state=42)\n",
        "rf_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-13T23:01:05.345244Z",
          "iopub.execute_input": "2024-07-13T23:01:05.345829Z",
          "iopub.status.idle": "2024-07-13T23:01:05.671862Z",
          "shell.execute_reply.started": "2024-07-13T23:01:05.345786Z",
          "shell.execute_reply": "2024-07-13T23:01:05.670171Z"
        },
        "trusted": true,
        "id": "Nxdg6XTM7hAd",
        "outputId": "135183c3-0ba3-4b47-8380-8b3b893251c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FOR prediction and evaluation, use the encoded values and then decode when necessary"
      ],
      "metadata": {
        "id": "k_iRNx8x7hAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Predict on the validation set\n",
        "# y_val_pred_rf = rf_clf.predict(X_val)\n",
        "\n",
        "# # Evaluate using encoded values\n",
        "# accuracy_rf = accuracy_score(y_val, y_val_pred_rf)\n",
        "# classification_rep_rf = classification_report(y_val, y_val_pred_rf)\n",
        "\n",
        "# print(\"\\nRandom Forest Model:\")\n",
        "# print(f\"Accuracy: {accuracy_rf}\")\n",
        "# print(f\"Classification Report:\\n{classification_rep_rf}\")\n",
        "\n",
        "# # If you need to see the actual 'Y' and 'N' values:\n",
        "# y_val_decoded = loan_status_le.inverse_transform(y_val)\n",
        "# y_val_pred_rf_decoded = loan_status_le.inverse_transform(y_val_pred_rf)"
      ],
      "metadata": {
        "trusted": true,
        "id": "OTcP1CIu7hAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FOR THE FINAL PREDICTION ON THE TEST SET"
      ],
      "metadata": {
        "id": "xQjm2fnJ7hAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose the better model for final prediction\n",
        "final_model = rf_clf  # or whichever model you choose\n",
        "\n",
        "# Predict on the test set\n",
        "X_test = test_data.drop('Loan_ID', axis=1)\n",
        "test_preds = final_model.predict(X_test)\n",
        "\n",
        "# Decode predictions\n",
        "test_preds_decoded = loan_status_le.inverse_transform(test_preds)\n",
        "\n",
        "# Prepare the submission file\n",
        "submission = pd.DataFrame({'Loan_ID': test_data['Loan_ID'], 'Loan_Status': test_preds_decoded})\n",
        "# submission.to_csv('Final_Submission.csv', index=False)\n",
        "\n",
        "print(\"\\nFinal Submission sample as Random forest is :\")\n",
        "print(submission.head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-13T23:01:13.515575Z",
          "iopub.execute_input": "2024-07-13T23:01:13.516024Z",
          "iopub.status.idle": "2024-07-13T23:01:13.551472Z",
          "shell.execute_reply.started": "2024-07-13T23:01:13.515991Z",
          "shell.execute_reply": "2024-07-13T23:01:13.549992Z"
        },
        "trusted": true,
        "id": "Jec4-RL97hAd",
        "outputId": "71b6fca1-912a-40c8-f950-7ccdbdcb5afa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Submission sample as Random forest is :\n",
            "    Loan_ID Loan_Status\n",
            "0  LP001015           Y\n",
            "1  LP001022           Y\n",
            "2  LP001031           Y\n",
            "3  LP001035           Y\n",
            "4  LP001051           N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test set\n",
        "X_test = test_data.drop('Loan_ID', axis=1)\n",
        "test_preds_lr = lin_reg.predict(X_test)\n",
        "test_preds_lr_binary = np.round(test_preds_lr).astype(int)\n",
        "\n",
        "# Decode predictions\n",
        "test_preds_decoded = loan_status_le.inverse_transform(test_preds_lr_binary)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-13T23:01:25.213143Z",
          "iopub.execute_input": "2024-07-13T23:01:25.213551Z",
          "iopub.status.idle": "2024-07-13T23:01:25.226042Z",
          "shell.execute_reply.started": "2024-07-13T23:01:25.213521Z",
          "shell.execute_reply": "2024-07-13T23:01:25.225046Z"
        },
        "trusted": true,
        "id": "F8uGcwHW7hAd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Logistic Regression model\n",
        "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
        "log_reg.fit(X_train, y_train)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-13T23:01:32.938868Z",
          "iopub.execute_input": "2024-07-13T23:01:32.939336Z",
          "iopub.status.idle": "2024-07-13T23:01:32.976854Z",
          "shell.execute_reply.started": "2024-07-13T23:01:32.9393Z",
          "shell.execute_reply": "2024-07-13T23:01:32.975848Z"
        },
        "trusted": true,
        "id": "jZyP0n4F7hAd",
        "outputId": "8dad115f-7c71-4be7-d864-31c3a653216b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose the better model for final prediction\n",
        "final_model = log_reg  # or whichever model you choose\n",
        "\n",
        "# Use the chosen model for final predictions\n",
        "X_test = test_data.drop('Loan_ID', axis=1)\n",
        "test_preds = final_model.predict(X_test)\n",
        "\n",
        "# Decode predictions\n",
        "test_preds_decoded = loan_status_le.inverse_transform(test_preds)\n",
        "\n",
        "# Prepare the submission file\n",
        "submission = pd.DataFrame({'Loan_ID': test_data['Loan_ID'], 'Loan_Status': test_preds_decoded})\n",
        "# submission.to_csv('Final_Submission.csv', index=False)\n",
        "\n",
        "print(\"\\nFinal Submission:\")\n",
        "print(submission.head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-13T23:01:37.167967Z",
          "iopub.execute_input": "2024-07-13T23:01:37.169235Z",
          "iopub.status.idle": "2024-07-13T23:01:37.186517Z",
          "shell.execute_reply.started": "2024-07-13T23:01:37.169195Z",
          "shell.execute_reply": "2024-07-13T23:01:37.183381Z"
        },
        "trusted": true,
        "id": "dYNm4ksx7hAe",
        "outputId": "6426d804-ece0-41f4-c70b-62d4a2aa1b08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Submission:\n",
            "    Loan_ID Loan_Status\n",
            "0  LP001015           Y\n",
            "1  LP001022           Y\n",
            "2  LP001031           Y\n",
            "3  LP001035           Y\n",
            "4  LP001051           Y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 10: Choose the Better Model and Make Final Predictions"
      ],
      "metadata": {
        "id": "g9Q-2h_u7hAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate Logistic Regression model\n",
        "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
        "log_reg.fit(X_train, y_train)\n",
        "y_val_pred_log = log_reg.predict(X_val)\n",
        "\n",
        "accuracy_log = accuracy_score(y_val, y_val_pred_log)\n",
        "classification_rep_log = classification_report(y_val, y_val_pred_log)\n",
        "\n",
        "print(\"Logistic Regression Model:\")\n",
        "print(f\"Accuracy: {accuracy_log}\")\n",
        "print(f\"Classification Report:\\n{classification_rep_log}\")\n",
        "\n",
        "# Train and evaluate Random Forest model\n",
        "rf_clf = RandomForestClassifier(random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "y_val_pred_rf = rf_clf.predict(X_val)\n",
        "\n",
        "accuracy_rf = accuracy_score(y_val, y_val_pred_rf)\n",
        "classification_rep_rf = classification_report(y_val, y_val_pred_rf)\n",
        "\n",
        "print(\"\\nRandom Forest Model:\")\n",
        "print(f\"Accuracy: {accuracy_rf}\")\n",
        "print(f\"Classification Report:\\n{classification_rep_rf}\")\n",
        "\n",
        "# Compare and choose the best model\n",
        "if accuracy_log > accuracy_rf:\n",
        "    print(\"\\nLogistic Regression performs better.\")\n",
        "    final_model = log_reg\n",
        "else:\n",
        "    print(\"\\nRandom Forest performs better.\")\n",
        "    final_model = rf_clf\n",
        "\n",
        "# Use the chosen model for final predictions\n",
        "X_test = test_data.drop('Loan_ID', axis=1)\n",
        "test_preds = final_model.predict(X_test)\n",
        "\n",
        "# Decode predictions\n",
        "test_preds_decoded = loan_status_le.inverse_transform(test_preds)\n",
        "\n",
        "# Prepare the submission file\n",
        "submission = pd.DataFrame({'Loan_ID': test_data['Loan_ID'], 'Loan_Status': test_preds_decoded})\n",
        "submission.to_csv('Final_Submission.csv', index=False)\n",
        "\n",
        "print(\"\\nFinal Submission:\")\n",
        "print(submission.head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-13T23:01:41.980393Z",
          "iopub.execute_input": "2024-07-13T23:01:41.980893Z",
          "iopub.status.idle": "2024-07-13T23:01:42.39551Z",
          "shell.execute_reply.started": "2024-07-13T23:01:41.980858Z",
          "shell.execute_reply": "2024-07-13T23:01:42.394116Z"
        },
        "trusted": true,
        "id": "ie4LoKcV7hAe",
        "outputId": "a26200f5-6fe3-4f29-8e90-d7a0a4ac9022",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Model:\n",
            "Accuracy: 0.7886178861788617\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.42      0.58        43\n",
            "           1       0.76      0.99      0.86        80\n",
            "\n",
            "    accuracy                           0.79       123\n",
            "   macro avg       0.85      0.70      0.72       123\n",
            "weighted avg       0.83      0.79      0.76       123\n",
            "\n",
            "\n",
            "Random Forest Model:\n",
            "Accuracy: 0.7804878048780488\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.42      0.57        43\n",
            "           1       0.76      0.97      0.85        80\n",
            "\n",
            "    accuracy                           0.78       123\n",
            "   macro avg       0.83      0.70      0.71       123\n",
            "weighted avg       0.81      0.78      0.75       123\n",
            "\n",
            "\n",
            "Logistic Regression performs better.\n",
            "\n",
            "Final Submission:\n",
            "    Loan_ID Loan_Status\n",
            "0  LP001015           Y\n",
            "1  LP001022           Y\n",
            "2  LP001031           Y\n",
            "3  LP001035           Y\n",
            "4  LP001051           Y\n"
          ]
        }
      ]
    }
  ]
}